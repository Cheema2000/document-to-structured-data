# Document to Structured Data Pipeline

## Overview
This project converts unstructured PDF documents into clean, structured, machine-readable data.  
It demonstrates a practical data engineering workflow including PDF ingestion, table extraction, data cleaning, and structured output generation.

The pipeline is designed to handle real-world documents (messy tables, inconsistent formatting) and transform them into reliable datasets suitable for analytics, automation, or downstream AI applications.

---

## Key Features
- PDF ingestion and processing
- Automatic table extraction from PDFs
- Data cleaning and normalization
- Structured output in CSV / JSON format
- Modular, script-based architecture
- Error handling for inconsistent data formats

---

## Tech Stack
- **Python 3**
- **Pandas** â€“ data cleaning and transformation
- **Tabula-py** â€“ PDF table extraction
- **Java (Tabula dependency)**
- **VS Code / Terminal**
- **Git & GitHub**

---

## Project Structure

document-to-structured-data/

â”‚
â”œâ”€â”€ data/

â”‚   â”œâ”€â”€ raw/            # Original PDF files

â”‚   â”œâ”€â”€ extracted/      # Extracted tables (CSV)

â”‚   â””â”€â”€ cleaned/        # Cleaned, structured datasets

â”‚
â”œâ”€â”€ src/

â”‚   â”œâ”€â”€ extract_tables.py   # Extract tables from PDF

â”‚   â”œâ”€â”€ clean_data.py       # Clean and normalize extracted data

â”‚   â””â”€â”€ utils.py            # Helper functions

â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

## Workflow
1. **Add PDF**
   - Place input PDF files inside the `data/raw/` directory.

2. **Extract Tables**
   ```bash
   python src/extract_tables.py
  â€¢ Extracts all detectable tables from the PDF.
  
	â€¢	Saves raw tables as CSV files.
  Output
  
	â€¢	Clean, structured CSV/JSON files ready for analysis or automation.

# Example Use Cases
	â€¢	Converting financial or survey PDFs into datasets
	â€¢	Preparing documents for analytics dashboards
	â€¢	Feeding structured data into AI/ML pipelines
	â€¢	Automating manual data extraction workflows

# Challenges Solved
	â€¢	Handling inconsistent table structures
	â€¢	Managing malformed CSV rows
	â€¢	Designing a reusable, modular pipeline
	â€¢	Working with real-world, non-clean data sources

# Future Enhancements
	â€¢	Add NLP-based document summarization
	â€¢	Integrate OCR for scanned PDFs
	â€¢	Add API endpoint for document upload
	â€¢	Automate pipeline execution
	â€¢	Improve table detection accuracy


Author

Muhammad Hamza
ðŸ”— LinkedInï¿¼
ðŸ“‚ GitHubï¿¼
